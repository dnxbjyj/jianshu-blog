　　最近在做毕设项目中，要用到一个语音识别的功能，主要目的是把用户说的话转换成文字，然后再做其他处理。找了多个语音识别的第三方SDK，比如百度语音识别、微信语音识别、科大讯飞语音识别，发现科大讯飞的比较好用。做了一个Demo程序，有详细的注释，在这里整理一下。

#（一） 准备工作

* 创建一个空的Android项目，比如项目名叫：SpeechRecognitionDemoJYJ。

* 首先要在[科大讯飞开放平台](http://www.xfyun.cn/)上注册，或者用QQ等第三方登录也行。

* 点击网站首页右上角的“控制台”，进入控制台。

* 按照说明创建一个应用，该应用名就叫SpeechRecognitionDemoJYJ，创建成功后会有一个AppID，记下来，编程的时候要用到。

* 点击SpeechRecognitionDemoJYJ后面的“开通服务”按钮，开通服务—>语音听写，进入语音听写—>下载当前应用对应的SDK。

* 下载Android版的SDK，将SDK包中libs目录下的Msc.jar和armeabi复制到Android工程的libs目录（如果工程无libs目录，请自行创建）中，并且因为还要用到语音听写Dialog，所以还要把SDK包中assets目录下的iflytek文件夹复制到工程的assets目录下，如下图所示。还要注意，每个不同的应用都要申请不同的AppID，并且要分别下载不同AppID对应的SDK，否则会出错。

![](http://upload-images.jianshu.io/upload_images/8819542-d38957f87647064a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

* 其他更详细的说明和资料可以参看[讯飞开放平台资料库](http://www.xfyun.cn/doccenter)。

# （二）上代码

Demo实现的功能很简单，就是点击一个按钮，弹出语音识别Dialog窗口，说话，说完了点击Dialog窗口后会把自动识别的文字结果显示在下方的EditText中。服务器返回的语音听写的结果是Json格式数据，最后还要对Json数据进行解析（具体解析方法参看我的这篇文章：[用GSON解析Json格式数据]()），解析出语音字符串。

* XML代码：

界面中有一个按钮，一个TextView和一个EditText，EditText用于显示语音识别的结果。

```xml
<LinearLayout xmlns:android="http://schemas.android.com/apk/res/android"
    android:layout_width="match_parent"
    android:layout_height="match_parent"
    android:orientation="vertical" >

    <Button
        android:id="@+id/listen_btn"
        android:layout_width="match_parent"
        android:layout_height="wrap_content"
        android:text="开始说话" />

    <TextView
        android:id="@+id/task_tv"
        android:layout_width="match_parent"
        android:layout_height="wrap_content"
        android:layout_margin="20dp"
        android:text="日程安排：" />

    <EditText
        android:id="@+id/content_et"
        android:layout_width="match_parent"
        android:layout_height="wrap_content"
        android:background="@android:drawable/editbox_dropdown_light_frame"
        android:cursorVisible="true"
        android:enabled="true"
        android:gravity="top"
        android:visibility="visible" />

</LinearLayout>
```

* MainActivity
```java
import java.lang.reflect.Type;
import java.util.List;

import com.example.speechrecognition.DictationResult;
import com.google.gson.Gson;
import com.google.gson.reflect.TypeToken;
import com.iflytek.cloud.RecognizerListener;
import com.iflytek.cloud.RecognizerResult;
import com.iflytek.cloud.SpeechConstant;
import com.iflytek.cloud.SpeechError;
import com.iflytek.cloud.SpeechRecognizer;
import com.iflytek.cloud.SpeechUtility;
import com.iflytek.cloud.ui.RecognizerDialog;
import com.iflytek.cloud.ui.RecognizerDialogListener;

import android.app.Activity;
import android.content.Context;
import android.os.Bundle;
import android.os.Handler;
import android.os.Message;
import android.util.Log;
import android.view.Menu;
import android.view.MenuItem;
import android.view.View;
import android.view.View.OnClickListener;
import android.view.inputmethod.InputMethodManager;
import android.widget.Button;
import android.widget.EditText;
import android.widget.TextView;

public class MainActivity extends Activity implements OnClickListener {
    private static String APPID = "569e39a1";

    private Button listenBtn;
    private EditText contentEt;

    // 听写结果字符串（多个Json的列表字符串）
    private String dictationResultStr = "[";

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);

        listenBtn = (Button) findViewById(R.id.listen_btn);
        contentEt = (EditText) findViewById(R.id.content_et);

        listenBtn.setOnClickListener(this);

    }

    @Override
    public void onClick(View v) {
        switch (v.getId()) {
        case R.id.listen_btn:

            dictationResultStr = "[";
            // 语音配置对象初始化
            SpeechUtility.createUtility(MainActivity.this, SpeechConstant.APPID
                    + "=" + APPID);

            // 1.创建SpeechRecognizer对象，第2个参数：本地听写时传InitListener
            SpeechRecognizer mIat = SpeechRecognizer.createRecognizer(
                    MainActivity.this, null);
            // 交互动画
            RecognizerDialog iatDialog = new RecognizerDialog(
                    MainActivity.this, null);
            // 2.设置听写参数，详见《科大讯飞MSC API手册(Android)》SpeechConstant类
            mIat.setParameter(SpeechConstant.DOMAIN, "iat"); // domain:域名
            mIat.setParameter(SpeechConstant.LANGUAGE, "zh_cn");
            mIat.setParameter(SpeechConstant.ACCENT, "mandarin"); // mandarin:普通话
            
            //3.开始听写
            iatDialog.setListener(new RecognizerDialogListener() {

                @Override
                public void onResult(RecognizerResult results, boolean isLast) {
                    // TODO 自动生成的方法存根
                    // Log.d("Result", results.getResultString());
                    // contentTv.setText(results.getResultString());
                    if (!isLast) {
                        dictationResultStr += results.getResultString() + ",";
                    } else {
                        dictationResultStr += results.getResultString() + "]";
                    }
                    if (isLast) {
                        // 解析Json列表字符串
                        Gson gson = new Gson();
                        List<DictationResult> dictationResultList = gson
                                .fromJson(dictationResultStr,
                                        new TypeToken<List<DictationResult>>() {
                                        }.getType());
                        String finalResult = "";
                        for (int i = 0; i < dictationResultList.size() - 1; i++) {
                            finalResult += dictationResultList.get(i)
                                    .toString();
                        }
                        contentEt.setText(finalResult);
                        
                        //获取焦点
                        contentEt.requestFocus();
                        
                        //将光标定位到文字最后，以便修改
                        contentEt.setSelection(finalResult.length());
                        
                        Log.d("From reall phone", finalResult);
                    }
                }

                @Override
                public void onError(SpeechError error) {
                    // TODO 自动生成的方法存根
                    error.getPlainDescription(true);
                }
            });

            // 开始听写
            iatDialog.show();

            break;
        default:
            break;
        }
    }
}
```

* 自定义的`com.example.speechrecognition.DictationResult`类的代码：

```java
import java.util.List;

/**
 * 解析语音听写返回结果Json格式字符串的模板类（多重嵌套Json）
 * 
 * 语音识别结果Json数据格式（单条数据）：
 * {"sn":1,"ls":true,"bg":0,"ed":0,"ws":[{"bg":0,"cw":[{"w":"今天","sc":0}]},
 * {"bg":0,"cw":{"w":"的","sc":0}]},{"bg":0,"cw":[{"w":"天气","sc":0}]},
 * {"bg":0,"cw":[{"w":"怎么样","sc":0}]},{"bg":0,"cw":[{"w":"。","sc":0}]}]}
 */
public class DictationResult {
    private String sn;
    private String ls;
    private String bg;
    private String ed;

    private List<Words> ws;

    public static class Words {
        private String bg;
        private List<Cw> cw;

        public static class Cw {
            private String w;
            private String sc;

            public String getW() {
                return w;
            }

            public void setW(String w) {
                this.w = w;
            }

            public String getSc() {
                return sc;
            }

            public void setSc(String sc) {
                this.sc = sc;
            }

            @Override
            public String toString() {
                return w;
            }
        }

        public String getBg() {
            return bg;
        }

        public void setBg(String bg) {
            this.bg = bg;
        }

        public List<Cw> getCw() {
            return cw;
        }

        public void setCw(List<Cw> cw) {
            this.cw = cw;
        }

        @Override
        public String toString() {
            String result = "";
            for (Cw cwTmp : cw) {
                result += cwTmp.toString();
            }
            return result;
        }
    }

    public String getSn() {
        return sn;
    }

    public void setSn(String sn) {
        this.sn = sn;
    }

    public String getLs() {
        return ls;
    }

    public void setLs(String ls) {
        this.ls = ls;
    }

    public String getBg() {
        return bg;
    }

    public void setBg(String bg) {
        this.bg = bg;
    }

    public String getEd() {
        return ed;
    }

    public void setEd(String ed) {
        this.ed = ed;
    }

    public List<Words> getWs() {
        return ws;
    }

    public void setWs(List<Words> ws) {
        this.ws = ws;
    }

    @Override
    public String toString() {
        String result = "";
        for (Words wsTmp : ws) {
            result += wsTmp.toString();
        }
        return result;
    }
}
```
* AndroidManifest.xml中申请权限：

```xml
<!-- 连接网络权限，用于执行云端语音能力 -->
    <uses-permission android:name="android.permission.INTERNET"/>
    <!-- 获取手机录音机使用权限，听写、识别、语义理解需要用到此权限  -->
    <uses-permission android:name="android.permission.RECORD_AUDIO"/> 
    <!--读取网络信息状态 -->  
    <uses-permission android:name="android.permission.ACCESS_NETWORK_STATE"/>  
    <!--获取当前wifi状态 -->  
    <uses-permission android:name="android.permission.ACCESS_WIFI_STATE"/>  
    <!--允许程序改变网络连接状态 -->
    <uses-permission android:name="android.permission.CHANGE_NETWORK_STATE"/>
    <!--读取手机信息权限 -->  
    <uses-permission android:name="android.permission.READ_PHONE_STATE"/>  
    <!--读取联系人权限，上传联系人需要用到此权限 -->  
    <uses-permission android:name="android.permission.READ_CONTACTS"/>
```

* 测试：模拟器无法打开录音机，是不能在上面测试的，要用真机测试。测试结果如下图：

![](http://upload-images.jianshu.io/upload_images/8819542-ece7930f04a074a3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

